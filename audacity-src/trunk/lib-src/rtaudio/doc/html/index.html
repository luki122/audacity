<HTML>
<HEAD>
<TITLE>The RtAudio Tutorial</TITLE>
<LINK HREF="doxygen.css" REL="stylesheet" TYPE="text/css">
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<CENTER>
<a class="qindex" href="index.html">Tutorial</a> &nbsp; <a class="qindex" href="annotated.html">Class/Enum List</a> &nbsp; <a class="qindex" href="files.html">File List</a> &nbsp; <a class="qindex" href="functions.html">Compound Members</a> &nbsp; </CENTER>
<HR>
<!-- Generated by Doxygen 1.3.4 -->
<h1>The <a class="el" href="classRtAudio.html">RtAudio</a> Tutorial </h1>
<p>
<center><a class="el" href="index.html#intro">Introduction</a> &nbsp;&nbsp; <a class="el" href="index.html#changes">What's New (Version 3.0)</a> &nbsp;&nbsp;<a class="el" href="index.html#download">Download</a> &nbsp;&nbsp; <a class="el" href="index.html#start">Getting Started</a> &nbsp;&nbsp; <a class="el" href="index.html#error">Error Handling</a> &nbsp;&nbsp; <a class="el" href="index.html#probing">Probing Device Capabilities</a> &nbsp;&nbsp; <a class="el" href="index.html#settings">Device Settings</a> &nbsp;&nbsp; <a class="el" href="index.html#playbackb">Playback (blocking functionality)</a> &nbsp;&nbsp; <a class="el" href="index.html#playbackc">Playback (callback functionality)</a> &nbsp;&nbsp; <a class="el" href="index.html#recording">Recording</a> &nbsp;&nbsp; <a class="el" href="index.html#duplex">Duplex Mode</a> &nbsp;&nbsp; <a class="el" href="index.html#multi">Using Simultaneous Multiple APIs</a> &nbsp;&nbsp; <a class="el" href="index.html#methods">Summary of Methods</a> &nbsp;&nbsp; <a class="el" href="index.html#compiling">Compiling</a> &nbsp;&nbsp; <a class="el" href="index.html#debug">Debugging</a> &nbsp;&nbsp; <a class="el" href="index.html#apinotes">API Notes</a> &nbsp;&nbsp; <a class="el" href="index.html#acknowledge">Acknowledgements</a> &nbsp;&nbsp; <a class="el" href="index.html#license">License</a></center><h2><a class="anchor" name="intro">
Introduction</a></h2>
<a class="el" href="classRtAudio.html">RtAudio</a> is a set of C++ classes which provide a common API (Application Programming Interface) for realtime audio input/output across Linux (native ALSA, JACK, and OSS), Macintosh OS X, SGI, and Windows (DirectSound and ASIO) operating systems. <a class="el" href="classRtAudio.html">RtAudio</a> significantly simplifies the process of interacting with computer audio hardware. It was designed with the following goals:<p>
<ul>
<li>
object oriented C++ design </li>
<li>
simple, common API across all supported platforms </li>
<li>
only two header files and one source file for easy inclusion in programming projects </li>
<li>
allow simultaneous multi-api support </li>
<li>
blocking functionality </li>
<li>
callback functionality </li>
<li>
extensive audio device parameter control </li>
<li>
audio device capability probing </li>
<li>
automatic internal conversion for data format, channel number compensation, de-interleaving, and byte-swapping </li>
</ul>
<p>
<a class="el" href="classRtAudio.html">RtAudio</a> incorporates the concept of audio streams, which represent audio output (playback) and/or input (recording). Available audio devices and their capabilities can be enumerated and then specified when opening a stream. Where applicable, multiple API support can be compiled and a particular API specified when creating an <a class="el" href="classRtAudio.html">RtAudio</a> instance. See the <a class="el" href="index.html#apinotes">API Notes</a> section for information specific to each of the supported audio APIs.<p>
The <a class="el" href="classRtAudio.html">RtAudio</a> API provides both blocking (synchronous) and callback (asynchronous) functionality. Callbacks are typically used in conjunction with graphical user interfaces (GUI). Blocking functionality is often necessary for explicit control of multiple input/output stream synchronization or when audio must be synchronized with other system events.<h2><a class="anchor" name="changes">
What's New (Version 3.0)</a></h2>
<a class="el" href="classRtAudio.html">RtAudio</a> now allows simultaneous multi-api support. For example, you can compile <a class="el" href="classRtAudio.html">RtAudio</a> to provide both DirectSound and ASIO support on Windows platforms or ALSA, JACK, and OSS support on Linux platforms. This was accomplished by creating an abstract base class, RtApi, with subclasses for each supported API (RtApiAlsa, RtApiJack, RtApiOss, RtApiDs, RtApiAsio, RtApiCore, and RtApiAl). The class <a class="el" href="classRtAudio.html">RtAudio</a> is now a "controller" which creates an instance of an RtApi subclass based on the user's API choice via an optional <a class="el" href="classRtAudio.html#w8">RtAudio::RtAudioApi</a> instantiation argument. If no API is specified, <a class="el" href="classRtAudio.html">RtAudio</a> attempts to make a "logical" API selection.<p>
Support for the JACK low-latency audio server has been added with this version of <a class="el" href="classRtAudio.html">RtAudio</a>. It is necessary to have the JACK server running before creating an instance of <a class="el" href="classRtAudio.html">RtAudio</a>.<p>
Several API changes have been made in version 3.0 of <a class="el" href="classRtAudio.html">RtAudio</a> in an effort to provide more consistent behavior across all supported audio APIs. The most significant of these changes is that multiple stream support from a single <a class="el" href="classRtAudio.html">RtAudio</a> instance has been discontinued. As a result, stream identifier input arguments are no longer required. Also, the RtAudio::streamWillBlock() function was poorly supported by most APIs and has been deprecated (though the function still exists in those subclasses of RtApi that do allow it to be implemented).<p>
The <a class="el" href="classRtAudio.html#a7">RtAudio::getDeviceInfo()</a> function was modified to return a globally defined <a class="el" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a> structure. This structure is a simplified version of the previous RTAUDIO_DEVICE structure. In addition, the RTAUDIO_FORMAT structure was renamed RtAudioFormat and defined globally within <a class="el" href="RtAudio_8h.html">RtAudio.h</a>. These changes were made for clarity and to better conform with standard C++ programming practices.<p>
The <a class="el" href="classRtError.html">RtError</a> class declaration and definition have been extracted to a separate file (<a class="el" href="RtError_8h.html">RtError.h</a>). This was done in preparation for a new release of the RtMidi class (planned for Summer 2004).<h2><a class="anchor" name="download">
Download</a></h2>
Latest Release (22 March 2004): <a href="http://music.mcgill.ca/~gary/rtaudio/release/rtaudio-3.0.1.tar.gz">Version 3.0.1 (200 kB tar/gzipped)</a><h2><a class="anchor" name="start">
Getting Started</a></h2>
With version 3.0, it is now possible to compile multiple API support on a given platform and to specify an API choice during class instantiation. In the examples that follow, no API will be specified (in which case, <a class="el" href="classRtAudio.html">RtAudio</a> attempts to select the most "logical" available API).<p>
The first thing that must be done when using <a class="el" href="classRtAudio.html">RtAudio</a> is to create an instance of the class. The default constructor scans the underlying audio system to verify that at least one device is available. <a class="el" href="classRtAudio.html">RtAudio</a> often uses C++ exceptions to report errors, necessitating try/catch blocks around most member functions. The following code example demonstrates default object construction and destruction:<p>
<div class="fragment"><pre><span class="preprocessor">#include "RtAudio.h"</span>

<span class="keywordtype">int</span> main()
{
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Default RtAudio constructor</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    <span class="comment">// Handle the exception here</span>
    error.printMessage();
  }

  <span class="comment">// Clean up</span>
  <span class="keyword">delete</span> audio;
}
</pre></div><p>
Obviously, this example doesn't demonstrate any of the real functionality of <a class="el" href="classRtAudio.html">RtAudio</a>. However, all uses of <a class="el" href="classRtAudio.html">RtAudio</a> must begin with a constructor (either default or overloaded varieties) and must end with class destruction. Further, it is necessary that all class methods which can throw a C++ exception be called within a try/catch block.<h2><a class="anchor" name="error">
Error Handling</a></h2>
<a class="el" href="classRtAudio.html">RtAudio</a> uses a C++ exception handler called <a class="el" href="classRtError.html">RtError</a>, which is declared and defined in <a class="el" href="RtError_8h.html">RtError.h</a>. The <a class="el" href="classRtError.html">RtError</a> class is quite simple but it does allow errors to be "caught" by <a class="el" href="classRtError.html#w11">RtError::Type</a>. Almost all <a class="el" href="classRtAudio.html">RtAudio</a> methods can "throw" an <a class="el" href="classRtError.html">RtError</a>, most typically if a driver error occurs or a stream function is called when no stream is open. There are a number of cases within <a class="el" href="classRtAudio.html">RtAudio</a> where warning messages may be displayed but an exception is not thrown. There is a protected <a class="el" href="classRtAudio.html">RtAudio</a> method, error(), which can be modified to globally control how these messages are handled and reported. By default, error messages are not automatically displayed in <a class="el" href="classRtAudio.html">RtAudio</a> unless the preprocessor definition __RTAUDIO_DEBUG__ is defined. Messages associated with caught exceptions can be displayed with, for example, the <a class="el" href="classRtError.html#a2">RtError::printMessage()</a> function.<h2><a class="anchor" name="probing">
Probing Device Capabilities</a></h2>
A programmer may wish to query the available audio device capabilities before deciding which to use. The following example outlines how this can be done.<p>
<div class="fragment"><pre><span class="comment">// probe.cpp</span>

<span class="preprocessor">#include &lt;iostream&gt;</span>
<span class="preprocessor">#include "RtAudio.h"</span>

<span class="keywordtype">int</span> main()
{
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Default RtAudio constructor</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    exit(EXIT_FAILURE);
  }

  <span class="comment">// Determine the number of devices available</span>
  <span class="keywordtype">int</span> devices = audio-&gt;<a class="code" href="classRtAudio.html#a6">getDeviceCount</a>();

  <span class="comment">// Scan through devices for various capabilities</span>
  <a class="code" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a> info;
  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=1; i&lt;=devices; i++) {

    <span class="keywordflow">try</span> {
      info = audio-&gt;<a class="code" href="classRtAudio.html#a7">getDeviceInfo</a>(i);
    }
    <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
      error.printMessage();
      <span class="keywordflow">break</span>;
    }

    <span class="comment">// Print, for example, the maximum number of output channels for each device</span>
    std::cout &lt;&lt; <span class="stringliteral">"device = "</span> &lt;&lt; i;
    std::cout &lt;&lt; <span class="stringliteral">": maximum output channels = "</span> &lt;&lt; info.<a class="code" href="structRtAudioDeviceInfo.html#o2">outputChannels</a> &lt;&lt; <span class="stringliteral">"\n"</span>;
  }

  <span class="comment">// Clean up</span>
  <span class="keyword">delete</span> audio;

  <span class="keywordflow">return</span> 0;
}
</pre></div><p>
The <a class="el" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a> structure is defined in <a class="el" href="RtAudio_8h.html">RtAudio.h</a> and provides a variety of information useful in assessing the capabilities of a device:<p>
<div class="fragment"><pre>  <span class="keyword">typedef</span> <span class="keyword">struct </span><a class="code" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a>{
    std::string <a class="code" href="structRtAudioDeviceInfo.html#o0">name</a>;             <span class="comment">// Character string device identifier.</span>
    <span class="keywordtype">bool</span> <a class="code" href="structRtAudioDeviceInfo.html#o1">probed</a>;                  <span class="comment">// true if the device capabilities were successfully probed.</span>
    <span class="keywordtype">int</span> <a class="code" href="structRtAudioDeviceInfo.html#o2">outputChannels</a>;           <span class="comment">// Maximum output channels supported by device.</span>
    <span class="keywordtype">int</span> <a class="code" href="structRtAudioDeviceInfo.html#o3">inputChannels</a>;            <span class="comment">// Maximum input channels supported by device.</span>
    <span class="keywordtype">int</span> <a class="code" href="structRtAudioDeviceInfo.html#o4">duplexChannels</a>;           <span class="comment">// Maximum simultaneous input/output channels supported by device.</span>
    <span class="keywordtype">bool</span> <a class="code" href="structRtAudioDeviceInfo.html#o5">isDefault</a>;               <span class="comment">// true if this is the default output or input device.</span>
    std::vector&lt;int&gt; <a class="code" href="structRtAudioDeviceInfo.html#o6">sampleRates</a>; <span class="comment">// Supported sample rates.</span>
    RtAudioFormat <a class="code" href="structRtAudioDeviceInfo.html#o7">nativeFormats</a>;  <span class="comment">// Bit mask of supported data formats.</span>
  };
</pre></div><p>
The following data formats are defined and fully supported by <a class="el" href="classRtAudio.html">RtAudio</a>:<p>
<div class="fragment"><pre>  <span class="keyword">typedef</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> RtAudioFormat;
  <span class="keyword">static</span> <span class="keyword">const</span> RtAudioFormat  RTAUDIO_SINT8;   <span class="comment">// Signed 8-bit integer</span>
  <span class="keyword">static</span> <span class="keyword">const</span> RtAudioFormat  RTAUDIO_SINT16;  <span class="comment">// Signed 16-bit integer</span>
  <span class="keyword">static</span> <span class="keyword">const</span> RtAudioFormat  RTAUDIO_SINT24;  <span class="comment">// Signed 24-bit integer (upper 3 bytes of 32-bit signed integer.)</span>
  <span class="keyword">static</span> <span class="keyword">const</span> RtAudioFormat  RTAUDIO_SINT32;  <span class="comment">// Signed 32-bit integer</span>
  <span class="keyword">static</span> <span class="keyword">const</span> RtAudioFormat  RTAUDIO_FLOAT32; <span class="comment">// 32-bit float normalized between +/- 1.0</span>
  <span class="keyword">static</span> <span class="keyword">const</span> RtAudioFormat  RTAUDIO_FLOAT64; <span class="comment">// 64-bit double normalized between +/- 1.0</span>
</pre></div><p>
The <em>nativeFormats</em> member of the <a class="el" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a> structure is a bit mask of the above formats which are natively supported by the device. However, <a class="el" href="classRtAudio.html">RtAudio</a> will automatically provide format conversion if a particular format is not natively supported. When the <em>probed</em> member of the <a class="el" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a> structure is false, the remaining structure members are undefined and the device is probably unuseable.<p>
While some audio devices may require a minimum channel value greater than one, <a class="el" href="classRtAudio.html">RtAudio</a> will provide automatic channel number compensation when the number of channels set by the user is less than that required by the device. Channel compensation is <em>NOT</em> possible when the number of channels set by the user is greater than that supported by the device.<p>
It should be noted that the capabilities reported by a device driver or underlying audio API are not always accurate and/or may be dependent on a combination of device settings. For this reason, <a class="el" href="classRtAudio.html">RtAudio</a> does not typically rely on the queried values when attempting to open a stream.<h2><a class="anchor" name="settings">
Device Settings</a></h2>
The next step in using <a class="el" href="classRtAudio.html">RtAudio</a> is to open a stream with particular device and parameter settings.<p>
<div class="fragment"><pre><span class="preprocessor">#include "RtAudio.h"</span>

<span class="keywordtype">int</span> main()
{
  <span class="keywordtype">int</span> channels = 2;
  <span class="keywordtype">int</span> sampleRate = 44100;
  <span class="keywordtype">int</span> bufferSize = 256;  <span class="comment">// 256 sample frames</span>
  <span class="keywordtype">int</span> nBuffers = 4;      <span class="comment">// number of internal buffers used by device</span>
  <span class="keywordtype">int</span> device = 0;        <span class="comment">// 0 indicates the default or first available device</span>
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Instantiate RtAudio and open a stream within a try/catch block</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    exit(EXIT_FAILURE);
  }

  <span class="keywordflow">try</span> {
    audio-&gt;<a class="code" href="classRtAudio.html#a3">openStream</a>(device, channels, 0, 0, RTAUDIO_FLOAT32,
                      sampleRate, &amp;bufferSize, nBuffers);
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    <span class="comment">// Perhaps try other parameters?</span>
  }

  <span class="comment">// Clean up</span>
  <span class="keyword">delete</span> audio;

  <span class="keywordflow">return</span> 0;
}
</pre></div><p>
The <a class="el" href="classRtAudio.html#a3">RtAudio::openStream()</a> method attempts to open a stream with a specified set of parameter values. In this case, we attempt to open a two channel playback stream with the default output device, 32-bit floating point data, a sample rate of 44100 Hz, a frame rate of 256 sample frames per read/write, and 4 internal device buffers. When device = 0, <a class="el" href="classRtAudio.html">RtAudio</a> first attempts to open the default audio device with the given parameters. If that attempt fails, <a class="el" href="classRtAudio.html">RtAudio</a> searches through the remaining available devices in an effort to find a device which will meet the given parameters. If all attempts are unsuccessful, an <a class="el" href="classRtError.html">RtError</a> is thrown. When a non-zero device value is specified, an attempt is made to open that device <em>ONLY</em> (device = 1 specifies the first identified device, as reported by <a class="el" href="classRtAudio.html#a7">RtAudio::getDeviceInfo()</a>).<p>
<a class="el" href="classRtAudio.html">RtAudio</a> provides four signed integer and two floating point data formats which can be specified using the RtAudioFormat parameter values mentioned earlier. If the opened device does not natively support the given format, <a class="el" href="classRtAudio.html">RtAudio</a> will automatically perform the necessary data format conversion.<p>
The <em>bufferSize</em> parameter specifies the desired number of sample frames which will be written to and/or read from a device per write/read operation. The <em>nBuffers</em> parameter is used in setting the underlying device buffer parameters. Both the <em>bufferSize</em> and <em>nBuffers</em> parameters can be used to control stream latency though there is no guarantee that the passed values will be those used by a device (the <em>nBuffers</em> parameter is ignored when using the OS X CoreAudio, Linux Jack, and the Windows ASIO APIs). In general, lower values for both parameters will produce less latency but perhaps less robust performance. Both parameters can be specified with values of zero, in which case the smallest allowable values will be used. The <em>bufferSize</em> parameter is passed as a pointer and the actual value used by the stream is set during the device setup procedure. <em>bufferSize</em> values should be a power of two. Optimal and allowable buffer values tend to vary between systems and devices. Check the <a class="el" href="index.html#apinotes">API Notes</a> section for general guidelines.<p>
As noted earlier, the device capabilities reported by a driver or underlying audio API are not always accurate and/or may be dependent on a combination of device settings. Because of this, <a class="el" href="classRtAudio.html">RtAudio</a> does not attempt to query a device's capabilities or use previously reported values when opening a device. Instead, <a class="el" href="classRtAudio.html">RtAudio</a> simply attempts to set the given parameters on a specified device and then checks whether the setup is successful or not.<h2><a class="anchor" name="playbackb">
Playback (blocking functionality)</a></h2>
Once the device is open for playback, there are only a few final steps necessary for realtime audio output. We'll first provide an example (blocking functionality) and then discuss the details.<p>
<div class="fragment"><pre><span class="comment">// playback.cpp</span>

<span class="preprocessor">#include "RtAudio.h"</span>

<span class="keywordtype">int</span> main()
{
  <span class="keywordtype">int</span> count;
  <span class="keywordtype">int</span> channels = 2;
  <span class="keywordtype">int</span> sampleRate = 44100;
  <span class="keywordtype">int</span> bufferSize = 256;  <span class="comment">// 256 sample frames</span>
  <span class="keywordtype">int</span> nBuffers = 4;      <span class="comment">// number of internal buffers used by device</span>
  <span class="keywordtype">float</span> *buffer;
  <span class="keywordtype">int</span> device = 0;        <span class="comment">// 0 indicates the default or first available device</span>
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Open a stream during RtAudio instantiation</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>(device, channels, 0, 0, RTAUDIO_FLOAT32,
                        sampleRate, &amp;bufferSize, nBuffers);
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    exit(EXIT_FAILURE);
  }

  <span class="keywordflow">try</span> {
    <span class="comment">// Get a pointer to the stream buffer</span>
    buffer = (<span class="keywordtype">float</span> *) audio-&gt;<a class="code" href="classRtAudio.html#a8">getStreamBuffer</a>();

    <span class="comment">// Start the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a11">startStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    <span class="keywordflow">goto</span> cleanup;
  }

  <span class="comment">// An example loop which runs for 40000 sample frames</span>
  count = 0;
  <span class="keywordflow">while</span> (count &lt; 40000) {
    <span class="comment">// Generate your samples and fill the buffer with bufferSize sample frames of data</span>
    ...

    <span class="comment">// Trigger the output of the data buffer</span>
    <span class="keywordflow">try</span> {
      audio-&gt;<a class="code" href="classRtAudio.html#a9">tickStream</a>();
    }
    <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
      error.printMessage();
      <span class="keywordflow">goto</span> cleanup;
    }

    count += bufferSize;
  }

  <span class="keywordflow">try</span> {
    <span class="comment">// Stop and close the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a12">stopStream</a>();
    audio-&gt;<a class="code" href="classRtAudio.html#a10">closeStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
  }

 cleanup:
  <span class="keyword">delete</span> audio;

  <span class="keywordflow">return</span> 0;
}
</pre></div><p>
The first thing to notice in this example is that we attempt to open a stream during class instantiation with an overloaded constructor. This constructor simply combines the functionality of the default constructor, used earlier, and the <a class="el" href="classRtAudio.html#a3">RtAudio::openStream()</a> method. Again, we have specified a device value of 0, indicating that the default or first available device meeting the given parameters should be used. An attempt is made to open the stream with the specified <em>bufferSize</em> value. However, it is possible that the device will not accept this value, in which case the closest allowable size is used and returned via the pointer value. The constructor can fail if no available devices are found, or a memory allocation or device driver error occurs. Note that you should not call the <a class="el" href="classRtAudio.html">RtAudio</a> destructor if an exception is thrown during instantiation.<p>
Assuming the constructor is successful, it is necessary to get a pointer to the buffer, provided by <a class="el" href="classRtAudio.html">RtAudio</a>, for use in feeding data to/from the opened stream. Note that the user should <em>NOT</em> attempt to deallocate the stream buffer memory ... memory management for the stream buffer will be automatically controlled by <a class="el" href="classRtAudio.html">RtAudio</a>. After starting the stream with <a class="el" href="classRtAudio.html#a11">RtAudio::startStream()</a>, one simply fills that buffer, which is of length equal to the returned <em>bufferSize</em> value, with interleaved audio data (in the specified format) for playback. Finally, a call to the <a class="el" href="classRtAudio.html#a9">RtAudio::tickStream()</a> routine triggers a blocking write call for the stream.<p>
In general, one should call the <a class="el" href="classRtAudio.html#a12">RtAudio::stopStream()</a> and <a class="el" href="classRtAudio.html#a10">RtAudio::closeStream()</a> methods after finishing with a stream. However, both methods will implicitly be called during object destruction if necessary.<h2><a class="anchor" name="playbackc">
Playback (callback functionality)</a></h2>
The primary difference in using <a class="el" href="classRtAudio.html">RtAudio</a> with callback functionality involves the creation of a user-defined callback function. Here is an example which produces a sawtooth waveform for playback.<p>
<div class="fragment"><pre><span class="preprocessor">#include &lt;iostream&gt;</span>
<span class="preprocessor">#include "RtAudio.h"</span>

<span class="comment">// Two-channel sawtooth wave generator.</span>
<span class="keywordtype">int</span> sawtooth(<span class="keywordtype">char</span> *buffer, <span class="keywordtype">int</span> bufferSize, <span class="keywordtype">void</span> *data)
{
  <span class="keywordtype">int</span> i, j;
  <span class="keywordtype">double</span> *my_buffer = (<span class="keywordtype">double</span> *) buffer;
  <span class="keywordtype">double</span> *my_data = (<span class="keywordtype">double</span> *) data;

  <span class="comment">// Write interleaved audio data.</span>
  <span class="keywordflow">for</span> (i=0; i&lt;bufferSize; i++) {
    <span class="keywordflow">for</span> (j=0; j&lt;2; j++) {
      *my_buffer++ = my_data[j];

      my_data[j] += 0.005 * (j+1+(j*0.1));
      <span class="keywordflow">if</span> (my_data[j] &gt;= 1.0) my_data[j] -= 2.0;
    }
  }

  <span class="keywordflow">return</span> 0;
}

<span class="keywordtype">int</span> main()
{
  <span class="keywordtype">int</span> channels = 2;
  <span class="keywordtype">int</span> sampleRate = 44100;
  <span class="keywordtype">int</span> bufferSize = 256;  <span class="comment">// 256 sample frames</span>
  <span class="keywordtype">int</span> nBuffers = 4;      <span class="comment">// number of internal buffers used by device</span>
  <span class="keywordtype">int</span> device = 0;        <span class="comment">// 0 indicates the default or first available device</span>
  <span class="keywordtype">double</span> data[2];
  <span class="keywordtype">char</span> input;
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Open a stream during RtAudio instantiation</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>(device, channels, 0, 0, RTAUDIO_FLOAT64,
                        sampleRate, &amp;bufferSize, nBuffers);
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    exit(EXIT_FAILURE);
  }

  <span class="keywordflow">try</span> {
    <span class="comment">// Set the stream callback function</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a4">setStreamCallback</a>(&amp;sawtooth, (<span class="keywordtype">void</span> *)data);

    <span class="comment">// Start the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a11">startStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    <span class="keywordflow">goto</span> cleanup;
  }

  std::cout &lt;&lt; <span class="stringliteral">"\nPlaying ... press &lt;enter&gt; to quit.\n"</span>;
  std::cin.get(input);

  <span class="keywordflow">try</span> {
    <span class="comment">// Stop and close the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a12">stopStream</a>();
    audio-&gt;<a class="code" href="classRtAudio.html#a10">closeStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
  }

 cleanup:
  <span class="keyword">delete</span> audio;

  <span class="keywordflow">return</span> 0;
}
</pre></div><p>
After opening the device in exactly the same way as the previous example (except with a data format change), we must set our callback function for the stream using <a class="el" href="classRtAudio.html#a4">RtAudio::setStreamCallback()</a>. When the underlying audio API uses blocking calls (OSS, ALSA, SGI, and Windows DirectSound), this method will spawn a new process (or thread) which automatically calls the callback function when more data is needed. Callback-based audio APIs (OS X CoreAudio Linux Jack, and ASIO) implement their own event notification schemes. Note that the callback function is called only when the stream is "running" (between calls to the <a class="el" href="classRtAudio.html#a11">RtAudio::startStream()</a> and <a class="el" href="classRtAudio.html#a12">RtAudio::stopStream()</a> methods). The last argument to <a class="el" href="classRtAudio.html#a4">RtAudio::setStreamCallback()</a> is a pointer to arbitrary data that you wish to access from within your callback function.<p>
In this example, we stop the stream with an explicit call to <a class="el" href="classRtAudio.html#a12">RtAudio::stopStream()</a>. When using callback functionality, it is also possible to stop a stream by returning a non-zero value from the callback function.<p>
Once set with <a class="el" href="classRtAudio.html#a4">RtAudio::setStreamCallback</a>, the callback process exists for the life of the stream (until the stream is closed with <a class="el" href="classRtAudio.html#a10">RtAudio::closeStream()</a> or the <a class="el" href="classRtAudio.html">RtAudio</a> instance is deleted). It is possible to disassociate a callback function and cancel its process for an open stream using the <a class="el" href="classRtAudio.html#a5">RtAudio::cancelStreamCallback()</a> method. The stream can then be used with blocking functionality or a new callback can be associated with it.<h2><a class="anchor" name="recording">
Recording</a></h2>
Using <a class="el" href="classRtAudio.html">RtAudio</a> for audio input is almost identical to the way it is used for playback. Here's the blocking playback example rewritten for recording:<p>
<div class="fragment"><pre><span class="comment">// record.cpp</span>

<span class="preprocessor">#include "RtAudio.h"</span>

<span class="keywordtype">int</span> main()
{
  <span class="keywordtype">int</span> count;
  <span class="keywordtype">int</span> channels = 2;
  <span class="keywordtype">int</span> sampleRate = 44100;
  <span class="keywordtype">int</span> bufferSize = 256;  <span class="comment">// 256 sample frames</span>
  <span class="keywordtype">int</span> nBuffers = 4;      <span class="comment">// number of internal buffers used by device</span>
  <span class="keywordtype">float</span> *buffer;
  <span class="keywordtype">int</span> device = 0;        <span class="comment">// 0 indicates the default or first available device</span>
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Instantiate RtAudio and open a stream.</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>(&amp;stream, 0, 0, device, channels,
                        RTAUDIO_FLOAT32, sampleRate, &amp;bufferSize, nBuffers);
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    exit(EXIT_FAILURE);
  }

  <span class="keywordflow">try</span> {
    <span class="comment">// Get a pointer to the stream buffer</span>
    buffer = (<span class="keywordtype">float</span> *) audio-&gt;<a class="code" href="classRtAudio.html#a8">getStreamBuffer</a>();

    <span class="comment">// Start the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a11">startStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    <span class="keywordflow">goto</span> cleanup;
  }

  <span class="comment">// An example loop which runs for about 40000 sample frames</span>
  count = 0;
  <span class="keywordflow">while</span> (count &lt; 40000) {

    <span class="comment">// Read a buffer of data</span>
    <span class="keywordflow">try</span> {
      audio-&gt;<a class="code" href="classRtAudio.html#a9">tickStream</a>();
    }
    <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
      error.printMessage();
      <span class="keywordflow">goto</span> cleanup;
    }

    <span class="comment">// Process the input samples (bufferSize sample frames) that were read</span>
    ...

    count += bufferSize;
  }

  <span class="keywordflow">try</span> {
    <span class="comment">// Stop the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a12">stopStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
  }

 cleanup:
  <span class="keyword">delete</span> audio;

  <span class="keywordflow">return</span> 0;
}
</pre></div><p>
In this example, the stream was opened for recording with a non-zero <em>inputChannels</em> value. The only other difference between this example and that for playback involves the order of data processing in the loop, where it is necessary to first read a buffer of input data before manipulating it.<h2><a class="anchor" name="duplex">
Duplex Mode</a></h2>
Finally, it is easy to use <a class="el" href="classRtAudio.html">RtAudio</a> for simultaneous audio input/output, or duplex operation. In this example, we use a callback function and simply scale the input data before sending it back to the output.<p>
<div class="fragment"><pre><span class="comment">// duplex.cpp</span>

<span class="preprocessor">#include &lt;iostream&gt;</span>
<span class="preprocessor">#include "RtAudio.h"</span>

<span class="comment">// Pass-through function.</span>
<span class="keywordtype">int</span> scale(<span class="keywordtype">char</span> *buffer, <span class="keywordtype">int</span> bufferSize, <span class="keywordtype">void</span> *)
{
  <span class="comment">// Note: do nothing here for pass through.</span>
  <span class="keywordtype">double</span> *my_buffer = (<span class="keywordtype">double</span> *) buffer;

  <span class="comment">// Scale input data for output.</span>
  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;bufferSize; i++) {
    <span class="comment">// Do for two channels.</span>
    *my_buffer++ *= 0.5;
    *my_buffer++ *= 0.5;
  }

  <span class="keywordflow">return</span> 0;
}

<span class="keywordtype">int</span> main()
{
  <span class="keywordtype">int</span> channels = 2;
  <span class="keywordtype">int</span> sampleRate = 44100;
  <span class="keywordtype">int</span> bufferSize = 256;  <span class="comment">// 256 sample frames</span>
  <span class="keywordtype">int</span> nBuffers = 4;      <span class="comment">// number of internal buffers used by device</span>
  <span class="keywordtype">int</span> device = 0;        <span class="comment">// 0 indicates the default or first available device</span>
  <span class="keywordtype">char</span> input;
  <a class="code" href="classRtAudio.html">RtAudio</a> *audio;

  <span class="comment">// Open a stream during RtAudio instantiation</span>
  <span class="keywordflow">try</span> {
    audio = <span class="keyword">new</span> <a class="code" href="classRtAudio.html">RtAudio</a>(device, channels, device, channels, RTAUDIO_FLOAT64,
                        sampleRate, &amp;bufferSize, nBuffers);
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    exit(EXIT_FAILURE);
  }

  <span class="keywordflow">try</span> {
    <span class="comment">// Set the stream callback function</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a4">setStreamCallback</a>(&amp;scale, NULL);

    <span class="comment">// Start the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a11">startStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
    <span class="keywordflow">goto</span> cleanup;
  }

  std::cout &lt;&lt; <span class="stringliteral">"\nRunning duplex ... press &lt;enter&gt; to quit.\n"</span>;
  std::cin.get(input);

  <span class="keywordflow">try</span> {
    <span class="comment">// Stop and close the stream</span>
    audio-&gt;<a class="code" href="classRtAudio.html#a12">stopStream</a>();
    audio-&gt;<a class="code" href="classRtAudio.html#a10">closeStream</a>();
  }
  <span class="keywordflow">catch</span> (<a class="code" href="classRtError.html">RtError</a> &amp;error) {
    error.printMessage();
  }

 cleanup:
  <span class="keyword">delete</span> audio;

  <span class="keywordflow">return</span> 0;
}
</pre></div><p>
When an <a class="el" href="classRtAudio.html">RtAudio</a> stream is running in duplex mode (nonzero input <em>AND</em> output channels), the audio write (playback) operation always occurs before the audio read (record) operation. This sequence allows the use of a single buffer to store both output and input data.<p>
As we see with this example, the write-read sequence of operations does not preclude the use of <a class="el" href="classRtAudio.html">RtAudio</a> in situations where input data is first processed and then output through a duplex stream. When the stream buffer is first allocated, it is initialized with zeros, which produces no audible result when output to the device. In this example, anything recorded by the audio stream input will be scaled and played out during the next round of audio processing.<p>
Note that duplex operation can also be achieved by opening one output stream instance and one input stream instance using the same or different devices. However, there may be timing problems when attempting to use two different devices, due to possible device clock variations, unless a common external "sync" is provided. This becomes even more difficult to achieve using two separate callback streams because it is not possible to <em>explicitly</em> control the calling order of the callback functions.<h2><a class="anchor" name="multi">
Using Simultaneous Multiple APIs</a></h2>
Because support for each audio API is encapsulated in a specific RtApi subclass, it is possible to compile and instantiate multiple API-specific subclasses on a given operating system. For example, one can compile both the RtApiDs and RtApiAsio classes on Windows operating systems by providing the appropriate preprocessor definitions, include files, and libraries for each. In a run-time situation, one might first attempt to determine whether any ASIO device drivers exist. This can be done by specifying the api argument <a class="el" href="classRtAudio.html#w8w6">RtAudio::WINDOWS_ASIO</a> when attempting to create an instance of <a class="el" href="classRtAudio.html">RtAudio</a>. If an <a class="el" href="classRtError.html">RtError</a> is thrown (indicating no available drivers), then an instance of <a class="el" href="classRtAudio.html">RtAudio</a> with the api argument <a class="el" href="classRtAudio.html#w8w7">RtAudio::WINDOWS_DS</a> can be created. Alternately, if no api argument is specified, <a class="el" href="classRtAudio.html">RtAudio</a> will first look for ASIO drivers and then DirectSound drivers (on Linux systems, the default API search order is Jack, Alsa, and finally OSS). In theory, it should also be possible to have separate instances of <a class="el" href="classRtAudio.html">RtAudio</a> open at the same time with different underlying audio API support, though this has not been tested. It is difficult to know how well different audio APIs can simultaneously coexist on a given operating system. In particular, it is most unlikely that the same device could be simultaneously controlled with two different audio APIs.<h2><a class="anchor" name="methods">
Summary of Methods</a></h2>
The following is a short summary of public methods (not including constructors and the destructor) provided by <a class="el" href="classRtAudio.html">RtAudio</a>:<p>
<ul>
<li>
<a class="el" href="classRtAudio.html#a3">RtAudio::openStream()</a>: opens a stream with the specified parameters. </li>
<li>
<a class="el" href="classRtAudio.html#a4">RtAudio::setStreamCallback()</a>: sets a user-defined callback function for the stream. </li>
<li>
<a class="el" href="classRtAudio.html#a5">RtAudio::cancelStreamCallback()</a>: cancels a callback process and function for the stream. </li>
<li>
<a class="el" href="classRtAudio.html#a6">RtAudio::getDeviceCount()</a>: returns the number of audio devices available. </li>
<li>
<a class="el" href="classRtAudio.html#a7">RtAudio::getDeviceInfo()</a>: returns an <a class="el" href="structRtAudioDeviceInfo.html">RtAudioDeviceInfo</a> structure for a specified device. </li>
<li>
<a class="el" href="classRtAudio.html#a8">RtAudio::getStreamBuffer()</a>: returns a pointer to the stream buffer. </li>
<li>
<a class="el" href="classRtAudio.html#a9">RtAudio::tickStream()</a>: triggers processing of input/output data for the stream (blocking). </li>
<li>
<a class="el" href="classRtAudio.html#a10">RtAudio::closeStream()</a>: closes the stream (implicitly called during object destruction). </li>
<li>
<a class="el" href="classRtAudio.html#a11">RtAudio::startStream()</a>: (re)starts the stream, typically after it has been stopped with either stopStream() or abortStream() or after first opening the stream. </li>
<li>
<a class="el" href="classRtAudio.html#a12">RtAudio::stopStream()</a>: stops the stream, allowing any remaining samples in the queue to be played out and/or read in. This does not implicitly call <a class="el" href="classRtAudio.html#a10">RtAudio::closeStream()</a>. </li>
<li>
<a class="el" href="classRtAudio.html#a13">RtAudio::abortStream()</a>: stops the stream, discarding any remaining samples in the queue. This does not implicitly call closeStream(). </li>
</ul>
<h2><a class="anchor" name="compiling">
Compiling</a></h2>
In order to compile <a class="el" href="classRtAudio.html">RtAudio</a> for a specific OS and audio API, it is necessary to supply the appropriate preprocessor definition and library within the compiler statement: <p>
<table border="2" cols="5" width="100%" cellspacing="3" cellpadding="3">
<tr bgcolor="beige">
<td width="5%"><b>OS:</b> </td><td width="5%"><b>Audio API:</b> </td><td width="5%"><b>C++ Class:</b> </td><td width="5%"><b>Preprocessor Definition:</b> </td><td width="5%"><b>Library or Framework:</b> </td><td><b>Example Compiler Statement:</b>  </td></tr>
<tr>
<td>Linux </td><td>ALSA </td><td>RtApiAlsa </td><td>__LINUX_ALSA__ </td><td><code>asound, pthread</code> </td><td><code>g++ -Wall -D__LINUX_ALSA__ -o probe probe.cpp RtAudio.cpp -lasound -lpthread</code>  </td></tr>
<tr>
<td>Linux </td><td>Jack Audio Server </td><td>RtApiJack </td><td>__LINUX_JACK__ </td><td><code>jack, pthread</code> </td><td><code>g++ -Wall -D__LINUX_JACK__ -o probe probe.cpp RtAudio.cpp `pkg-config --cflags --libs jack` -lpthread</code>  </td></tr>
<tr>
<td>Linux </td><td>OSS </td><td>RtApiOss </td><td>__LINUX_OSS__ </td><td><code>pthread</code> </td><td><code>g++ -Wall -D__LINUX_OSS__ -o probe probe.cpp RtAudio.cpp -lpthread</code>  </td></tr>
<tr>
<td>Macintosh OS X </td><td>CoreAudio </td><td>RtApiCore </td><td>__MACOSX_CORE__ </td><td><code>pthread, stdc++, CoreAudio</code> </td><td><code>g++ -Wall -D__MACOSX_CORE__ -o probe probe.cpp RtAudio.cpp -framework CoreAudio -lpthread</code>  </td></tr>
<tr>
<td>Irix </td><td>AL </td><td>RtApiAl </td><td>__IRIX_AL__ </td><td><code>audio, pthread</code> </td><td><code>CC -Wall -D__IRIX_AL__ -o probe probe.cpp RtAudio.cpp -laudio -lpthread</code>  </td></tr>
<tr>
<td>Windows </td><td>Direct Sound </td><td>RtApiDs </td><td>__WINDOWS_DS__ </td><td><code>dsound.lib (ver. 5.0 or higher), multithreaded</code> </td><td><em>compiler specific</em>  </td></tr>
<tr>
<td>Windows </td><td>ASIO </td><td>RtApiAsio </td><td>__WINDOWS_ASIO__ </td><td><em>various ASIO header and source files</em> </td><td><em>compiler specific</em>  </td></tr>
</table>
<p>
The example compiler statements above could be used to compile the <code>probe.cpp</code> example file, assuming that <code>probe.cpp</code>, <code><a class="el" href="RtAudio_8h.html">RtAudio.h</a></code>, <code><a class="el" href="RtError_8h.html">RtError.h</a></code>, and <code>RtAudio.cpp</code> all exist in the same directory.<h2><a class="anchor" name="debug">
Debugging</a></h2>
If you are having problems getting <a class="el" href="classRtAudio.html">RtAudio</a> to run on your system, try passing the preprocessor definition <code>__RTAUDIO_DEBUG__</code> to the compiler (or uncomment the definition at the bottom of <a class="el" href="RtAudio_8h.html">RtAudio.h</a>). A variety of warning messages will be displayed which may help in determining the problem. Also try using the programs included in the <code>test</code> directory. The program <code>info</code> displays the queried capabilities of all hardware devices found.<h2><a class="anchor" name="apinotes">
API Notes</a></h2>
<a class="el" href="classRtAudio.html">RtAudio</a> is designed to provide a common API across the various supported operating systems and audio libraries. Despite that, some issues should be mentioned with regard to each.<h3><a class="anchor" name="linux">
Linux:</a></h3>
<a class="el" href="classRtAudio.html">RtAudio</a> for Linux was developed under Redhat distributions 7.0 - Fedora. Three different audio APIs are supported on Linux platforms: OSS, <a href="http://www.alsa-project.org/">ALSA</a>, and <a href="http://jackit.sourceforge.net/">Jack</a>. The OSS API has existed for at least 6 years and the Linux kernel is distributed with free versions of OSS audio drivers. Therefore, a generic Linux system is most likely to have OSS support (though the availability and quality of OSS drivers for new hardware is decreasing). The ALSA API, although relatively new, is now part of the Linux development kernel and offers significantly better functionality than the OSS API. <a class="el" href="classRtAudio.html">RtAudio</a> provides support for the 1.0 and higher versions of ALSA. Jack, which is still in development, is a low-latency audio server, written primarily for the GNU/Linux operating system. It can connect a number of different applications to an audio device, as well as allow them to share audio between themselves. Input/output latency on the order of 15 milliseconds can typically be achieved using any of the Linux APIs by fine-tuning the <a class="el" href="classRtAudio.html">RtAudio</a> buffer parameters (without kernel modifications). Latencies on the order of 5 milliseconds or less can be achieved using a low-latency kernel patch and increasing FIFO scheduling priority. The pthread library, which is used for callback functionality, is a standard component of all Linux distributions.<p>
The ALSA library includes OSS emulation support. That means that you can run programs compiled for the OSS API even when using the ALSA drivers and library. It should be noted however that OSS emulation under ALSA is not perfect. Specifically, channel number queries seem to consistently produce invalid results. While OSS emulation is successful for the majority of <a class="el" href="classRtAudio.html">RtAudio</a> tests, it is recommended that the native ALSA implementation of <a class="el" href="classRtAudio.html">RtAudio</a> be used on systems which have ALSA drivers installed.<p>
The ALSA implementation of <a class="el" href="classRtAudio.html">RtAudio</a> makes no use of the ALSA "plug" interface. All necessary data format conversions, channel compensation, de-interleaving, and byte-swapping is handled by internal <a class="el" href="classRtAudio.html">RtAudio</a> routines.<p>
The Jack API is based on a callback scheme. <a class="el" href="classRtAudio.html">RtAudio</a> provides blocking functionality, in addition to callback functionality, within the context of that behavior. It should be noted, however, that the best performance is achieved when using RtAudio's callback functionality with the Jack API. At the moment, only one <a class="el" href="classRtAudio.html">RtAudio</a> instance can be connected to the Jack server. Because <a class="el" href="classRtAudio.html">RtAudio</a> does not provide a mechanism for allowing the user to specify particular channels (or ports) of a device, it simply opens the first <em>N</em> enumerated Jack ports for input/output.<h3><a class="anchor" name="macosx">
Macintosh OS X (CoreAudio):</a></h3>
The Apple CoreAudio API is based on a callback scheme. <a class="el" href="classRtAudio.html">RtAudio</a> provides blocking functionality, in addition to callback functionality, within the context of that behavior. CoreAudio is designed to use a separate callback procedure for each of its audio devices. A single <a class="el" href="classRtAudio.html">RtAudio</a> duplex stream using two different devices is supported, though it cannot be guaranteed to always behave correctly because we cannot synchronize these two callbacks. This same functionality might be achieved with better synchrony by creating separate instances of <a class="el" href="classRtAudio.html">RtAudio</a> for each device and making use of <a class="el" href="classRtAudio.html">RtAudio</a> blocking calls (i.e. <a class="el" href="classRtAudio.html#a9">RtAudio::tickStream()</a>). The <em>numberOfBuffers</em> parameter to the <a class="el" href="classRtAudio.html#a3">RtAudio::openStream()</a> function has no affect in this implementation.<p>
It is not possible to have multiple instances of <a class="el" href="classRtAudio.html">RtAudio</a> accessing the same CoreAudio device.<h3><a class="anchor" name="irix">
Irix (SGI):</a></h3>
The Irix version of <a class="el" href="classRtAudio.html">RtAudio</a> was written and tested on an SGI Indy running Irix version 6.5.4 and the newer "al" audio library. <a class="el" href="classRtAudio.html">RtAudio</a> does not compile under Irix version 6.3, mainly because the C++ compiler is too old. Despite the relatively slow speed of the Indy, <a class="el" href="classRtAudio.html">RtAudio</a> was found to behave quite well and input/output latency was very good. No problems were found with respect to using the pthread library.<h3><a class="anchor" name="windowsds">
Windows (DirectSound):</a></h3>
In order to compile <a class="el" href="classRtAudio.html">RtAudio</a> under Windows for the DirectSound API, you must have the header and source files for DirectSound version 5.0 or higher. As far as I know, there is no DirectSoundCapture support for Windows NT. Audio output latency with DirectSound can be reasonably good (on the order of 20 milliseconds). On the other hand, input audio latency tends to be terrible (100 milliseconds or more). Further, DirectSound drivers tend to crash easily when experimenting with buffer parameters. On my system, I found it necessary to use values around nBuffers = 8 and bufferSize = 512 to avoid crashes. <a class="el" href="classRtAudio.html">RtAudio</a> was originally developed with Visual C++ version 6.0.<h3><a class="anchor" name="windowsasio">
Windows (ASIO):</a></h3>
The Steinberg ASIO audio API is based on a callback scheme. In addition, the API allows only a single device driver to be loaded and accessed at a time. ASIO device drivers must be supplied by audio hardware manufacturers, though ASIO emulation is possible on top of systems with DirectSound drivers. The <em>numberOfBuffers</em> parameter to the <a class="el" href="classRtAudio.html#a3">RtAudio::openStream()</a> function has no affect in this implementation.<p>
A number of ASIO source and header files are required for use with <a class="el" href="classRtAudio.html">RtAudio</a>. Specifically, an <a class="el" href="classRtAudio.html">RtAudio</a> project must include the following files: <code>asio.h,cpp; asiodrivers.h,cpp; asiolist.h,cpp; asiodrvr.h; asiosys.h; ginclude.h; iasiodrv.h</code>. The Visual C++ projects found in <code>/tests/Windows/</code> compile both ASIO and DirectSound support.<h2><a class="anchor" name="acknowledge">
Acknowledgements</a></h2>
The <a class="el" href="classRtAudio.html">RtAudio</a> API incorporates many of the concepts developed in the <a href="http://www.portaudio.com/">PortAudio</a> project by Phil Burk and Ross Bencina. Early development also incorporated ideas from Bill Schottstaedt's <a href="http://www-ccrma.stanford.edu/software/snd/sndlib/">sndlib</a>. The CCRMA <a href="http://www-ccrma.stanford.edu/groups/soundwire/">SoundWire group</a> provided valuable feedback during the API proposal stages.<p>
The early 2.0 version of <a class="el" href="classRtAudio.html">RtAudio</a> was slowly developed over the course of many months while in residence at the <a href="http://www.iua.upf.es/">Institut Universitari de L'Audiovisual (IUA)</a> in Barcelona, Spain and the <a href="http://www.acoustics.hut.fi/">Laboratory of Acoustics and Audio Signal Processing</a> at the Helsinki University of Technology, Finland. Much subsequent development happened while working at the <a href="http://www-ccrma.stanford.edu/">Center for Computer Research in Music and Acoustics (CCRMA)</a> at <a href="http://www.stanford.edu/">Stanford University</a>. The most recent version of <a class="el" href="classRtAudio.html">RtAudio</a> was finished while working as an assistant professor of <a href="http://www.music.mcgill.ca/musictech/">Music Technology</a> at <a href="http://www.mcgill.ca/">McGill University</a>. This work was supported in part by the United States Air Force Office of Scientific Research (grant #F49620-99-1-0293).<h2><a class="anchor" name="license">
License</a></h2>
<a class="el" href="classRtAudio.html">RtAudio</a>: a realtime audio i/o C++ classes<br>
 Copyright (c) 2001-2004 Gary P. Scavone<p>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:<p>
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.<p>
Any person wishing to distribute modifications to the Software is requested to send the modifications to the original developer so that they can be incorporated into the canonical version.<p>
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. <HR>

<table><tr><td><img src="../images/mcgill.gif" width=165></td>
  <td>&copy;2001-2004 Gary P. Scavone, McGill University. All Rights Reserved.<br>
  Maintained by Gary P. Scavone, <a href="mailto:gary@music.mcgill.ca">gary@music.mcgill.ca</a></td></tr>
</table>

</BODY>
</HTML>
